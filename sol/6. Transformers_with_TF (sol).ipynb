{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"6. Transformers_with_TF (sol).ipynb","provenance":[{"file_id":"18vuacGTCCoecm-Qp4wYJEzmoo1eW3wrI","timestamp":1590414998879}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python [default]","language":"python","name":"python3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"9afd5361c65f4c48a7bee485dc953fe9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e7d611ad5d03434a89646823d5507480","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b77714e6ff664b779489c4132b17a52c","IPY_MODEL_a07b6bd22fe749178d31eee7897ed105","IPY_MODEL_28c0093ed8b24b2dae989f3c15be23cb"]}},"e7d611ad5d03434a89646823d5507480":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b77714e6ff664b779489c4132b17a52c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_44ffb0126d054dbe92a05f9c2172054c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_559de5a6309a4900af3a0f064d0d7319"}},"a07b6bd22fe749178d31eee7897ed105":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_bdcb76aecfbf410aa5839963123be711","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":570,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":570,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a7d7812b93c944e494a898fb2e986965"}},"28c0093ed8b24b2dae989f3c15be23cb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e87f6e5ff738460c95e59426d0e6fe7e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 570/570 [00:00&lt;00:00, 12.9kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2d7d32c9d1794e09b19765616dd085f2"}},"44ffb0126d054dbe92a05f9c2172054c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"559de5a6309a4900af3a0f064d0d7319":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bdcb76aecfbf410aa5839963123be711":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a7d7812b93c944e494a898fb2e986965":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e87f6e5ff738460c95e59426d0e6fe7e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2d7d32c9d1794e09b19765616dd085f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e757f62779d9408d8b39181836ce61f2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1000bbc63b814e329659eea70bb2775f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9c8d08f429d9486fb36040770922d5c6","IPY_MODEL_3cf1553d4d5147baaea6ed76940bcc10","IPY_MODEL_1473c16592f749a9a2edc7cec4374b7f"]}},"1000bbc63b814e329659eea70bb2775f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9c8d08f429d9486fb36040770922d5c6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_617857d38dda4d3a898b1fdba7436e94","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c102fe499fcd481baf8670d4edd11df9"}},"3cf1553d4d5147baaea6ed76940bcc10":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_1e2363af5a994879b0b86618a8407683","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":526681800,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":526681800,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_33c1bea80c4a4511bdd7a40d73be94bf"}},"1473c16592f749a9a2edc7cec4374b7f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6f0f41c5155b4fd4aeb0e6c117784979","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 502M/502M [00:19&lt;00:00, 32.8MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cecbe4f3934549119995c4c3129f227d"}},"617857d38dda4d3a898b1fdba7436e94":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c102fe499fcd481baf8670d4edd11df9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1e2363af5a994879b0b86618a8407683":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"33c1bea80c4a4511bdd7a40d73be94bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6f0f41c5155b4fd4aeb0e6c117784979":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"cecbe4f3934549119995c4c3129f227d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"51b0767d6b2947fabe3827debc722033":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0508d3b477874c03acd600012da01c1f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_506d9ec99a7748bc87b6c7cd8ac7e43c","IPY_MODEL_293783758b4e44768f968f1c139c7e23","IPY_MODEL_d58323ca4c4f4edd81d858204f15680d"]}},"0508d3b477874c03acd600012da01c1f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"506d9ec99a7748bc87b6c7cd8ac7e43c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_14f4e7c9607545a4880dced0aa02ba75","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4e6be1988324433dad71a4254396aaae"}},"293783758b4e44768f968f1c139c7e23":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0af0f672c2b74edca041f40af84796bf","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":213450,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":213450,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_918db383059446449cdceefebe3fac08"}},"d58323ca4c4f4edd81d858204f15680d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_060ff4dcc8934a56950f07ef7bedb1fb","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 208k/208k [00:00&lt;00:00, 343kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_aee279ffd0864c4b803fe5b2b28b4c8e"}},"14f4e7c9607545a4880dced0aa02ba75":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4e6be1988324433dad71a4254396aaae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0af0f672c2b74edca041f40af84796bf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"918db383059446449cdceefebe3fac08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"060ff4dcc8934a56950f07ef7bedb1fb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"aee279ffd0864c4b803fe5b2b28b4c8e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"55adf9d420d542769001da9324b79ffd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ee55f72dc1254b65b84eba156199620d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9243d62a9fcb465a82e8266231e9e94c","IPY_MODEL_5249407f36da453faea99d3db301fc0b","IPY_MODEL_e04bdc1a24eb401ca331e284a08383ee"]}},"ee55f72dc1254b65b84eba156199620d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9243d62a9fcb465a82e8266231e9e94c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_93e65de3e4884d9091d49a35feaa642b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b4d251d3b6b9428b9a8385e7e7e0c079"}},"5249407f36da453faea99d3db301fc0b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_fb3f60764c57439e8bfd714eb715f949","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":29,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":29,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_79e40d4d16644ff29c5fee061971e49f"}},"e04bdc1a24eb401ca331e284a08383ee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_47dad16786e8440694f283fd4cc8921d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 29.0/29.0 [00:00&lt;00:00, 474B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3652d80dcaa44794a53e3845ccd263d6"}},"93e65de3e4884d9091d49a35feaa642b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b4d251d3b6b9428b9a8385e7e7e0c079":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fb3f60764c57439e8bfd714eb715f949":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"79e40d4d16644ff29c5fee061971e49f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"47dad16786e8440694f283fd4cc8921d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3652d80dcaa44794a53e3845ccd263d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"73039a7ba76847028ff30cd5b1ac026b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_62644c31d1294aa59b02755872cf8004","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0833250b5398486a89a53fc0c8379086","IPY_MODEL_d699bbf4dab440d9ae4b5d099ad25de5","IPY_MODEL_8ad0172f379f4f52aaf032f83bc23049"]}},"62644c31d1294aa59b02755872cf8004":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0833250b5398486a89a53fc0c8379086":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9f66402d94b5471b9e072e77384a4e5b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_793e69c7af874524b61616bd312c48fd"}},"d699bbf4dab440d9ae4b5d099ad25de5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_220c43b0acd14534a2425e5346c0cfba","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":435797,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":435797,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_14511484bfa74d73ae03f5c9181fcf49"}},"8ad0172f379f4f52aaf032f83bc23049":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fd3dd9d36b854051bfb1727155bbfd02","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 426k/426k [00:00&lt;00:00, 634kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b7901af24d5a4f30b64a08df320e1b81"}},"9f66402d94b5471b9e072e77384a4e5b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"793e69c7af874524b61616bd312c48fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"220c43b0acd14534a2425e5346c0cfba":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"14511484bfa74d73ae03f5c9181fcf49":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fd3dd9d36b854051bfb1727155bbfd02":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b7901af24d5a4f30b64a08df320e1b81":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"imyaVBbcIBVq"},"source":["# Lab 5: Sentiment Analysis with fine-tuned Transformers\n","\n","In this lab session, you will fine-tune a **Transformer** based pre-trained language model for sentiment analysis. Transfer learning with large pre-trained language models has been shown to be successful strategy to achieve state-of-the-art performances. In this lab we'll learn how to do transfer learning with large pre-trained neural language models like BERT. \n","\n","More concretely, in this lab session will learn the following:\n","\n","- Deploy and fine-tune transformers from the [Hugging Face library](https://github.com/huggingface/transformers)\n","- Preprocessing data for transformers archicture (word piece tokenizatiin)\n","- Implementation of Transformer-based classifier\n","\n","\n","\n","----\n","\n","## Transfer Learning\n"," \n","Figure below shows how to fine-tune a transformer on a downstream task. Here, the fine-tuning task is sentiment analysis of movie reviews. As learned from theory, we will use the knowledge encoded in the Transformer to learn better our target task. So our sentiment classifier has two main components: 1) the text encoder based on BERT (which doesn't know anything about sentiments, but knows something about English), and 2) the component dedicated to sentiment classification (a simple feed-forward layer). In other words, BERT will generate the sentence embeddings of the input and pass to the classifier layer to the prediction. When we fine-tune our classifier we'll change BERT's parameters as well, and make it to learn specific aspects of the task.\n","\n"," ![](http://ixa2.si.ehu.es/~jibloleo/uc3m_dl4nlp/img/fine-tuning.png)\n","\n","\n","Advantages of these types of architectures and learning:\n","\n","- Unlimited amount of unlabelled text data can be scraped from the web with very little effort to train a large language model.\n","- Transformer is a feed-forward architecture that allows highly parallelized, efficient training on huge datasets, with the objective of simply predicting words based on their context ([check the tutorial on strategy learning for sequence classification](https://colab.research.google.com/drive/1yWaLpCWImXZE2fPV0ZYDdWWI8f52__9A#scrollTo=MGqVkG2-7qfu)).\n","- Although pre-training a language model can be expensive, fine-tuning can be done in a single GPU most of the times, as tipically it requiere few learning epochs. \n"]},{"cell_type":"markdown","metadata":{"id":"yWHDCCqPIBVr"},"source":["## 1. Loading the data\n","We'll use the same data for sentiement analysis used in previous sessions. So first, we need to mount our Drive account in order to get access to the sentiment analysis data ( Stanford Sentiment Treebank)."]},{"cell_type":"code","metadata":{"id":"ihLkOMT9OJDt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641474635914,"user_tz":-60,"elapsed":20898,"user":{"displayName":"Ander Barrena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgRxXTKl_X28G_aTFKEgcKsBAE_r5TE9B5ziwl2w=s64","userId":"06771498905541655767"}},"outputId":"8b18fa9b-6ef3-4c68-afa9-2d2f6d58e345"},"source":["# Mount Drive files\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"xZhrDTCkIBVt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641474642819,"user_tz":-60,"elapsed":6908,"user":{"displayName":"Ander Barrena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgRxXTKl_X28G_aTFKEgcKsBAE_r5TE9B5ziwl2w=s64","userId":"06771498905541655767"}},"outputId":"96eb916b-20c4-4ec9-b35f-5c6b3ecd590d"},"source":["import numpy as np\n","import pandas as pd\n","import re\n","\n","import tensorflow as tf\n","from sklearn.utils import shuffle\n","\n","## for replicability of results\n","np.random.seed(1)\n","tf.random.set_seed(2)\n","\n","# Let's do 2-way positive/negative classification instead of 5-way    \n","def load_sst_data(path,\n","                  easy_label_map={0:0, 1:0, 2:None, 3:1, 4:1}):\n","    data = []\n","    with open(path) as f:\n","        for i, line in enumerate(f): \n","            example = {}\n","            example['label'] = easy_label_map[int(line[1])]\n","            if example['label'] is None:\n","                continue\n","            \n","            # Strip out the parse information and the phrase labels---we don't need those here\n","            text = re.sub(r'\\s*(\\(\\d)|(\\))\\s*', '', line)\n","            example['text'] = text[1:]\n","            data.append(example)\n","    data = pd.DataFrame(data)\n","    return data\n","\n","def pretty_print(example):\n","    print('Label: {}\\nText: {}'.format(example['label'], example['text']))\n","\n","sst_home = 'drive/My Drive/Colab Notebooks/dl4nlp_labs/data/trees/'\n","training_set = load_sst_data(sst_home+'/train.txt')\n","dev_set = load_sst_data(sst_home+'/dev.txt')\n","test_set = load_sst_data(sst_home+'/test.txt')\n","\n","# Shuffle dataset\n","training_set = shuffle(training_set)\n","dev_set = shuffle(dev_set)\n","test_set = shuffle(test_set)\n","\n","# Obtain text and label vectors\n","train_texts = training_set.text\n","train_labels = training_set.label\n","\n","dev_texts = dev_set.text\n","dev_labels = dev_set.label\n","\n","test_texts = test_set.text\n","test_labels = test_set.label\n","\n","\n","print('Training size: {}'.format(len(training_set)))\n","print('Dev size: {}'.format(len(dev_set)))\n","print('Test size: {}'.format(len(test_set)))"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Training size: 6920\n","Dev size: 872\n","Test size: 1821\n"]}]},{"cell_type":"markdown","metadata":{"id":"yZqxg504JNIv"},"source":["## 2. Installing and seting up the Transformers library"]},{"cell_type":"code","metadata":{"id":"8I1LnTA4II71","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641474665999,"user_tz":-60,"elapsed":23191,"user":{"displayName":"Ander Barrena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgRxXTKl_X28G_aTFKEgcKsBAE_r5TE9B5ziwl2w=s64","userId":"06771498905541655767"}},"outputId":"fd4af29e-4aab-43b3-fee6-cd345be72b22"},"source":["# https://blog.tensorflow.org/2019/11/hugging-face-state-of-art-natural.html\n","!pip install transformers"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n","\u001b[K     |████████████████████████████████| 3.4 MB 4.3 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n","\u001b[K     |████████████████████████████████| 61 kB 508 kB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 49.1 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 40.6 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 55.4 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.2.1 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.15.0\n"]}]},{"cell_type":"markdown","metadata":{"id":"Q4ZJAgAVelDa"},"source":["Once the transformers library is installed, we can use it directly just creating three object of two classes:\n","\n","- **The tokenizer class**: the tokenizer class takes care of converting input  string in tensors of integers which are indices in a model vocabulary. The tokenization varies according to the model, therefore each model has its own tokenizer.\n","\n","- **The model class**: the model class holds the neural network modeling logic itself. When using a TensorFlow model, it inherits from tf.keras.layers. Layer which means it can be used very simply by the Keras’ fit API or make more complicated stuff. \n","\n","There is also **configuration class** that is also required unless you are not using the default values. With the configuration class we indicate everything related to hyperparaters such as number of layers, dropout and so on. Below is an example of a BERT configuration file, for the pre-trained weights bert-base-cased. \n","\n","```\n","{\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 28996\n","}\n","```\n"]},{"cell_type":"code","metadata":{"id":"G7FLj9htJFJW","colab":{"base_uri":"https://localhost:8080/","height":266,"referenced_widgets":["9afd5361c65f4c48a7bee485dc953fe9","e7d611ad5d03434a89646823d5507480","b77714e6ff664b779489c4132b17a52c","a07b6bd22fe749178d31eee7897ed105","28c0093ed8b24b2dae989f3c15be23cb","44ffb0126d054dbe92a05f9c2172054c","559de5a6309a4900af3a0f064d0d7319","bdcb76aecfbf410aa5839963123be711","a7d7812b93c944e494a898fb2e986965","e87f6e5ff738460c95e59426d0e6fe7e","2d7d32c9d1794e09b19765616dd085f2","e757f62779d9408d8b39181836ce61f2","1000bbc63b814e329659eea70bb2775f","9c8d08f429d9486fb36040770922d5c6","3cf1553d4d5147baaea6ed76940bcc10","1473c16592f749a9a2edc7cec4374b7f","617857d38dda4d3a898b1fdba7436e94","c102fe499fcd481baf8670d4edd11df9","1e2363af5a994879b0b86618a8407683","33c1bea80c4a4511bdd7a40d73be94bf","6f0f41c5155b4fd4aeb0e6c117784979","cecbe4f3934549119995c4c3129f227d","51b0767d6b2947fabe3827debc722033","0508d3b477874c03acd600012da01c1f","506d9ec99a7748bc87b6c7cd8ac7e43c","293783758b4e44768f968f1c139c7e23","d58323ca4c4f4edd81d858204f15680d","14f4e7c9607545a4880dced0aa02ba75","4e6be1988324433dad71a4254396aaae","0af0f672c2b74edca041f40af84796bf","918db383059446449cdceefebe3fac08","060ff4dcc8934a56950f07ef7bedb1fb","aee279ffd0864c4b803fe5b2b28b4c8e","55adf9d420d542769001da9324b79ffd","ee55f72dc1254b65b84eba156199620d","9243d62a9fcb465a82e8266231e9e94c","5249407f36da453faea99d3db301fc0b","e04bdc1a24eb401ca331e284a08383ee","93e65de3e4884d9091d49a35feaa642b","b4d251d3b6b9428b9a8385e7e7e0c079","fb3f60764c57439e8bfd714eb715f949","79e40d4d16644ff29c5fee061971e49f","47dad16786e8440694f283fd4cc8921d","3652d80dcaa44794a53e3845ccd263d6","73039a7ba76847028ff30cd5b1ac026b","62644c31d1294aa59b02755872cf8004","0833250b5398486a89a53fc0c8379086","d699bbf4dab440d9ae4b5d099ad25de5","8ad0172f379f4f52aaf032f83bc23049","9f66402d94b5471b9e072e77384a4e5b","793e69c7af874524b61616bd312c48fd","220c43b0acd14534a2425e5346c0cfba","14511484bfa74d73ae03f5c9181fcf49","fd3dd9d36b854051bfb1727155bbfd02","b7901af24d5a4f30b64a08df320e1b81"]},"executionInfo":{"status":"ok","timestamp":1641474711311,"user_tz":-60,"elapsed":45314,"user":{"displayName":"Ander Barrena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgRxXTKl_X28G_aTFKEgcKsBAE_r5TE9B5ziwl2w=s64","userId":"06771498905541655767"}},"outputId":"7bdceffd-dd05-4c2d-a807-4e202aa01c2c"},"source":["from transformers import TFBertForSequenceClassification, BertTokenizer\n","\n","model = TFBertForSequenceClassification.from_pretrained(\"bert-base-cased\")\n","tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n"],"execution_count":4,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9afd5361c65f4c48a7bee485dc953fe9","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e757f62779d9408d8b39181836ce61f2","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/502M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n","\n","Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"51b0767d6b2947fabe3827debc722033","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"55adf9d420d542769001da9324b79ffd","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"73039a7ba76847028ff30cd5b1ac026b","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/426k [00:00<?, ?B/s]"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"3U_bMFqMcINb"},"source":["Next we will define two helper function to 1) extract features from the tokenizer (`convert_examples_to_features`) and 2) convert the features to `tf.data.Dataset` object class (`convert_features_to_tf_dataset`). `tf.data.Dataset` is a convinient API that helps managing and iterating in efficient way the input and output data of the model.  For more information you can check the API in tensorflow web page: https://www.tensorflow.org/api_docs/python/tf/data/Dataset."]},{"cell_type":"code","metadata":{"id":"QAolNiqWJmM3","executionInfo":{"status":"ok","timestamp":1641474711311,"user_tz":-60,"elapsed":22,"user":{"displayName":"Ander Barrena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgRxXTKl_X28G_aTFKEgcKsBAE_r5TE9B5ziwl2w=s64","userId":"06771498905541655767"}}},"source":["from transformers import InputFeatures\n","\n","def convert_examples_to_features(texts, labels):\n","  labels = list(labels)\n","  batch_encoding = tokenizer.batch_encode_plus(texts, max_length=128, pad_to_max_length=True)\n","\n","  features = []\n","  for i in range(len(texts)):\n","      inputs = {k: batch_encoding[k][i] for k in batch_encoding}\n","\n","      feature = InputFeatures(**inputs, label=labels[i])\n","      features.append(feature)\n","\n","  for i, example in enumerate(texts[:5]):\n","      print(\"*** Example ***\")\n","      print(\"text: %s\" % (example))\n","      print(\"features: %s\" % features[i])\n","\n","  return features\n","\n","def convert_features_to_tf_dataset(features):\n","  def gen():\n","      for ex in features:\n","          yield (\n","              {\n","                  \"input_ids\": ex.input_ids,\n","                  \"attention_mask\": ex.attention_mask,\n","                  \"token_type_ids\": ex.token_type_ids,\n","              },\n","              ex.label,\n","          )\n","  dataset = tf.data.Dataset.from_generator(gen, \n","                                           ({\"input_ids\": tf.int32, \"attention_mask\": tf.int32, \"token_type_ids\": tf.int32}, tf.int64),\n","                                           (\n","                                               {\n","                                                \"input_ids\": tf.TensorShape([None]),\n","                                                \"attention_mask\": tf.TensorShape([None]),\n","                                                \"token_type_ids\": tf.TensorShape([None])\n","                                                },\n","                                            tf.TensorShape([]),\n","                                            ))\n","  return dataset"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v2OE1lWbh3P7"},"source":["Let's preprocess the training and development sets. Note that we use the `tf.data.Dataset` API to set the batch size to 32."]},{"cell_type":"code","metadata":{"id":"1r1LPqLIaW4_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641474716103,"user_tz":-60,"elapsed":4811,"user":{"displayName":"Ander Barrena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgRxXTKl_X28G_aTFKEgcKsBAE_r5TE9B5ziwl2w=s64","userId":"06771498905541655767"}},"outputId":"6f8ffea7-6343-4b55-df13-e8b8d03ee53e"},"source":["train_features = convert_examples_to_features(train_texts, train_labels)\n","train_dataset = convert_features_to_tf_dataset(train_features)\n","\n","dev_features = convert_examples_to_features(dev_texts, dev_labels)\n","dev_dataset = convert_features_to_tf_dataset(dev_features)\n","\n","train_dataset = train_dataset.shuffle(100).batch(32)\n","dev_dataset = dev_dataset.batch(32)"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2232: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["*** Example ***\n","text: It is dark , brooding and slow , and takes its central idea way too seriously .\n","features: InputFeatures(input_ids=[101, 1135, 1110, 1843, 117, 9304, 13465, 1158, 1105, 3345, 117, 1105, 2274, 1157, 2129, 1911, 1236, 1315, 5536, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\n","*** Example ***\n","text: To honestly address the flaws inherent in how medical aid is made available to American workers , a more balanced or fair portrayal of both sides will be needed .\n","features: InputFeatures(input_ids=[101, 1706, 12051, 4134, 1103, 24132, 17575, 1107, 1293, 2657, 4256, 1110, 1189, 1907, 1106, 1237, 3239, 117, 170, 1167, 12591, 1137, 4652, 14513, 1104, 1241, 3091, 1209, 1129, 1834, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\n","*** Example ***\n","text: A sad and rote exercise in milking a played-out idea -- a straight guy has to dress up in drag -- that shockingly manages to be even worse than its title would imply .\n","features: InputFeatures(input_ids=[101, 138, 6782, 1105, 24692, 1162, 6730, 1107, 6831, 1158, 170, 1307, 118, 1149, 1911, 118, 118, 170, 2632, 2564, 1144, 1106, 3642, 1146, 1107, 8194, 118, 118, 1115, 19196, 1193, 8701, 1106, 1129, 1256, 4146, 1190, 1157, 1641, 1156, 21276, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\n","*** Example ***\n","text: Ken Russell would love this .\n","features: InputFeatures(input_ids=[101, 5928, 5023, 1156, 1567, 1142, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n","*** Example ***\n","text: An incredibly irritating comedy about thoroughly vacuous people ... manages to embody the worst excesses of nouvelle vague without any of its sense of fun or energy .\n","features: InputFeatures(input_ids=[101, 1760, 12170, 178, 14791, 24558, 3789, 1164, 12678, 191, 7409, 8163, 1234, 119, 119, 119, 8701, 1106, 9712, 14637, 1103, 4997, 10116, 1279, 1104, 1185, 19581, 4838, 14673, 1443, 1251, 1104, 1157, 2305, 1104, 4106, 1137, 2308, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\n","*** Example ***\n","text: People cinema at its finest .\n","features: InputFeatures(input_ids=[101, 2563, 7678, 1120, 1157, 10812, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n","*** Example ***\n","text: Irwin is a man with enough charisma and audacity to carry a dozen films , but this particular result is ultimately held back from being something greater .\n","features: InputFeatures(input_ids=[101, 18819, 1110, 170, 1299, 1114, 1536, 22572, 26464, 1918, 1105, 12686, 1810, 9041, 1106, 3564, 170, 5955, 2441, 117, 1133, 1142, 2440, 1871, 1110, 4444, 1316, 1171, 1121, 1217, 1380, 3407, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\n","*** Example ***\n","text: If you 've ever entertained the notion of doing what the title of this film implies , what Sex With Strangers actually shows may put you off the idea forever .\n","features: InputFeatures(input_ids=[101, 1409, 1128, 112, 1396, 1518, 23745, 1103, 9162, 1104, 1833, 1184, 1103, 1641, 1104, 1142, 1273, 12942, 117, 1184, 9850, 1556, 19153, 1116, 2140, 2196, 1336, 1508, 1128, 1228, 1103, 1911, 5221, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\n","*** Example ***\n","text: There ought to be a directing license , so that Ed Burns can have his revoked .\n","features: InputFeatures(input_ids=[101, 1247, 11454, 1106, 1129, 170, 10404, 5941, 117, 1177, 1115, 5316, 9608, 1169, 1138, 1117, 25538, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\n","*** Example ***\n","text: It 's not that Kung Pow is n't funny some of the time -- it just is n't any funnier than bad martial arts movies are all by themselves , without all Oedekerk 's impish augmentation .\n","features: InputFeatures(input_ids=[101, 1135, 112, 188, 1136, 1115, 24120, 18959, 2246, 1110, 183, 112, 189, 6276, 1199, 1104, 1103, 1159, 118, 118, 1122, 1198, 1110, 183, 112, 189, 1251, 4106, 12682, 1190, 2213, 8317, 3959, 5558, 1132, 1155, 1118, 2310, 117, 1443, 1155, 152, 15018, 4188, 1377, 112, 188, 24034, 2944, 12686, 14294, 1891, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\n"]}]},{"cell_type":"markdown","metadata":{"id":"gZgauVk5jNhd"},"source":["The results of the tokenizer can be seen in the cell below. There are some differences if vary the tokenizer, but most of them provide the following information. \n","\n","- `input_ids`: list of token ids to be fed to a model. Remember that the tokens are subwords, and new tokens are included to indicate sentence separation or ending (`[SEP]`) as well as `[CLS]` token that allow the sentence classification .\n","\n","- `token_type_ids`: list of token type ids to be fed to a model. \n","\n","- `attention_mask`: list of indices specifying which tokens should be attended to by the model\n"]},{"cell_type":"code","metadata":{"id":"aue9cJVx_N65","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641474716103,"user_tz":-60,"elapsed":14,"user":{"displayName":"Ander Barrena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgRxXTKl_X28G_aTFKEgcKsBAE_r5TE9B5ziwl2w=s64","userId":"06771498905541655767"}},"outputId":"b91fc008-1eeb-4ca2-ff32-5d23a2a43555"},"source":["# take one bacth of 32 examples.\n","instance = list(train_dataset.take(1).as_numpy_iterator())\n","print(instance)"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["[({'input_ids': array([[  101,  1135,   112, ...,     0,     0,     0],\n","       [  101, 19143,  1200, ...,     0,     0,     0],\n","       [  101,  1409,  1175, ...,     0,     0,     0],\n","       ...,\n","       [  101,  9352, 24851, ...,     0,     0,     0],\n","       [  101,  2409,  1157, ...,     0,     0,     0],\n","       [  101,  2268, 12062, ...,     0,     0,     0]], dtype=int32), 'attention_mask': array([[1, 1, 1, ..., 0, 0, 0],\n","       [1, 1, 1, ..., 0, 0, 0],\n","       [1, 1, 1, ..., 0, 0, 0],\n","       ...,\n","       [1, 1, 1, ..., 0, 0, 0],\n","       [1, 1, 1, ..., 0, 0, 0],\n","       [1, 1, 1, ..., 0, 0, 0]], dtype=int32), 'token_type_ids': array([[0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0],\n","       ...,\n","       [0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0]], dtype=int32)}, array([0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0,\n","       1, 0, 1, 1, 1, 0, 1, 1, 1, 1]))]\n"]}]},{"cell_type":"markdown","metadata":{"id":"GorwYEWOcFWs"},"source":["## 3. Understanding the tokenizer\n","\n","When we preprocess the input text to be fed in BERT like encoder, we tipically make three steps: \n","\n","1. Break words into tokens (subwords). \n","2. Add the special tokens such as `[CLS]` and `[SEP]`. These special tokens are already included in the model's vocabulary, so they have their own token id.\n","3. Substitute the tokens with their corresponding ids. After this step will get the proper shape for BERT. \n","\n","The code cell bellow shows the results of the three steps. \n","\n","\n"]},{"cell_type":"code","metadata":{"id":"HFDfUY1UcWzS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641474716104,"user_tz":-60,"elapsed":11,"user":{"displayName":"Ander Barrena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgRxXTKl_X28G_aTFKEgcKsBAE_r5TE9B5ziwl2w=s64","userId":"06771498905541655767"}},"outputId":"736dd766-f799-4f08-b7c5-ec2b747d4458"},"source":["sentence1 = \"a visually stunning rumination on love.\"\n","sentence2 = \"There ought to be a directing license, so that Ed Burns can have his revoked.\"\n","\n","# Tokenize sentence\n","sentence1_tokenized = tokenizer.tokenize(sentence1)\n","print('0. INPUT SENTENCE: {}'.format(sentence1))\n","print('1. TOKENIZED SENTENCE: {}'.format(sentence1_tokenized))\n","\n","# Add Special tokens\n","sentence1_tokenized_with_special_tokens = ['[CLS]'] + sentence1_tokenized + ['[SEP]']\n","print('2. ADD [CLS], [SEP]: {}'.format(sentence1_tokenized_with_special_tokens))\n","sentence1_ids = tokenizer.convert_tokens_to_ids(sentence1_tokenized_with_special_tokens)\n","\n","# Convert to ids\n","print('3. SENTENCE IDS: {}'.format(sentence1_ids))"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["0. INPUT SENTENCE: a visually stunning rumination on love.\n","1. TOKENIZED SENTENCE: ['a', 'visually', 'stunning', 'r', '##umi', '##nation', 'on', 'love', '.']\n","2. ADD [CLS], [SEP]: ['[CLS]', 'a', 'visually', 'stunning', 'r', '##umi', '##nation', 'on', 'love', '.', '[SEP]']\n","3. SENTENCE IDS: [101, 170, 19924, 15660, 187, 14088, 9199, 1113, 1567, 119, 102]\n"]}]},{"cell_type":"markdown","metadata":{"id":"_68U0jC81wFA"},"source":["### Exercise 1:\n","- Can you see what happened to \"rumination\" after the tokenization? \n","- Can you identify the token ids for [CLS] and [SEP]?\n","\n","The tokenizer returns subwords instead of complete words. So it what happens with the \"rumination\" is that the tokenizer divides it into three components:\n","\n","```\n","'rumination' => 'r', '##umi', '##nation'\n","```\n","\n","Regarding the special tokens [CLS] and [SEP], they are transformed to the following token ids:\n","\n","```\n","'[CLS]' => 101\n","'[SEP]' => 102\n","```\n","-----"]},{"cell_type":"markdown","metadata":{"id":"GmPo2_4twYmE"},"source":["The three steps can be done with `encode` or `batch_encode_plus` functions. The first function takes single string and convert is to ids. Then second function is more convinient to preprocess larger input data. It returns all the requiered information (input_ids, token_type_ids, attention_mask, etc) in a python dictionary. "]},{"cell_type":"code","metadata":{"id":"RTYbni402ES0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641474716104,"user_tz":-60,"elapsed":10,"user":{"displayName":"Ander Barrena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgRxXTKl_X28G_aTFKEgcKsBAE_r5TE9B5ziwl2w=s64","userId":"06771498905541655767"}},"outputId":"8d71518e-df04-4b40-9de3-4722ce91d148"},"source":["# how tokenize and get the token ids with one funtions\n","sentence1_ids = tokenizer.encode(sentence1, add_special_tokens=True)\n","\n","print('SENTENCE IDS: {}'.format(sentence1_ids))\n","\n","# there are more convinient methods to preprocess the input data. \n","batch_encoding = tokenizer.batch_encode_plus(\n","        [sentence1], max_length=128, pad_to_max_length=True,\n","    )\n","print('ENCODE PLUS: {}'.format(batch_encoding))"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["SENTENCE IDS: [101, 170, 19924, 15660, 187, 14088, 9199, 1113, 1567, 119, 102]\n","ENCODE PLUS: {'input_ids': [[101, 170, 19924, 15660, 187, 14088, 9199, 1113, 1567, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2232: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]}]},{"cell_type":"markdown","metadata":{"id":"xhRQkPRa2KBL"},"source":["### Two sentences as input\n","\n","As you have seen in the theoretical part BERT is a masked language models that learns predicting masked words, and in addition it predicts if next sentence belongs after the first one. That's why BERT's tokenizer is ready to have two sentences as input. This way preprocessing the data is interesting for task like Semantic Textual Similiraty and Natural Language Inference. "]},{"cell_type":"code","metadata":{"id":"V2qZJTkFq8y6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641474716104,"user_tz":-60,"elapsed":9,"user":{"displayName":"Ander Barrena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgRxXTKl_X28G_aTFKEgcKsBAE_r5TE9B5ziwl2w=s64","userId":"06771498905541655767"}},"outputId":"2a444fb1-7fb4-4a5e-a6ea-0f9300759c01"},"source":["# how tokenize and get the token ids with one funtions\n","sentence_pair_ids = tokenizer.encode(text=sentence1, text_pair=sentence2, add_special_tokens=True)\n","\n","\n","# there are more convinient methods to preprocess the input data. \n","batch_encoding = tokenizer.batch_encode_plus(\n","        [(sentence1, sentence2)], max_length=128, pad_to_max_length=True,\n","    )\n","\n","print(\"SENTENCE PAIR IDS: {}\".format(sentence_pair_ids))\n"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["SENTENCE PAIR IDS: [101, 170, 19924, 15660, 187, 14088, 9199, 1113, 1567, 119, 102, 1247, 11454, 1106, 1129, 170, 10404, 5941, 117, 1177, 1115, 5316, 9608, 1169, 1138, 1117, 25538, 119, 102]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2232: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]}]},{"cell_type":"markdown","metadata":{"id":"fSeX9VzaFOAY"},"source":["### Exercise 2:\n","- From the IDs can you say which ids correspond to the first sentence and which to the second one? \n","\n","First sentence ids: \n","\n","```\n","170, 19924, 15660, 187, 14088, 9199, 1113, 1567, 119\n","```\n","\n","\n","Second setence ids:\n","```\n","1247, 11454, 1106, 1129, 170, 10404, 5941, 117, 1177, 1115, 5316, 9608, 1169, 1138, 1117, 25538, 119\n"," ```\n"]},{"cell_type":"markdown","metadata":{"id":"D80JtwZbWJ7C"},"source":["## 4. Fine-tune BERT as Sentence Classifier"]},{"cell_type":"code","metadata":{"id":"2vWeYpxdCmtC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641475890828,"user_tz":-60,"elapsed":1174732,"user":{"displayName":"Ander Barrena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgRxXTKl_X28G_aTFKEgcKsBAE_r5TE9B5ziwl2w=s64","userId":"06771498905541655767"}},"outputId":"5865cc42-5961-4496-8f00-fef390f058b9"},"source":["# Prepare training: Compile tf.keras model with optimizer, loss and learning rate schedule\n","optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0)\n","loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n","model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n","\n","# Train and evaluate using tf.keras.Model.fit()\n","history = model.fit(train_dataset, epochs=3, validation_data=dev_dataset)\n"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","217/217 [==============================] - 361s 2s/step - loss: 0.3743 - accuracy: 0.8361 - val_loss: 0.2422 - val_accuracy: 0.9071\n","Epoch 2/3\n","217/217 [==============================] - 329s 2s/step - loss: 0.1535 - accuracy: 0.9464 - val_loss: 0.2857 - val_accuracy: 0.9002\n","Epoch 3/3\n","217/217 [==============================] - 329s 2s/step - loss: 0.0590 - accuracy: 0.9806 - val_loss: 0.4036 - val_accuracy: 0.8922\n"]}]},{"cell_type":"code","metadata":{"id":"OMfta2vyKCXt","colab":{"base_uri":"https://localhost:8080/","height":572},"executionInfo":{"status":"ok","timestamp":1641475891506,"user_tz":-60,"elapsed":683,"user":{"displayName":"Ander Barrena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgRxXTKl_X28G_aTFKEgcKsBAE_r5TE9B5ziwl2w=s64","userId":"06771498905541655767"}},"outputId":"baae1d55-36bf-4d21-ac8c-22a583ced961"},"source":["import matplotlib.pyplot as plt\n","\n","# summarize history for accuracy\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'dev'], loc='upper left')\n","plt.show()\n","\n","# summarize history for accuracy\n","plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'dev'], loc='upper left')\n","plt.show()"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"Aeyowf06K11o"},"source":["A nice feature when fine-tuning a large model is that we do not need to train many epochs (the number of epochs depends on the size of the training set). In this case, it looks like just one epoch can be enough. "]},{"cell_type":"markdown","metadata":{"id":"6EsEkO3uG1et"},"source":["Once the model is fine-tuned for sentiment analysis we could evaluate it on the test set. In this we need to tokenized and convert to ids the input too. "]},{"cell_type":"code","metadata":{"id":"4KFUtfXzImAY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641475892142,"user_tz":-60,"elapsed":643,"user":{"displayName":"Ander Barrena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgRxXTKl_X28G_aTFKEgcKsBAE_r5TE9B5ziwl2w=s64","userId":"06771498905541655767"}},"outputId":"3d8ab899-4a46-47a9-eeae-e6296b5c3743"},"source":["test_features = convert_examples_to_features(test_texts, test_labels)\n","test_dataset = convert_features_to_tf_dataset(test_features)"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2232: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["*** Example ***\n","text: With Danilo Donati 's witty designs and Dante Spinotti 's luscious cinematography , this might have made a decent children 's movie -- if only Benigni had n't insisted on casting himself in the title role .\n","features: InputFeatures(input_ids=[101, 1556, 21555, 2858, 1790, 11745, 112, 188, 20787, 2340, 5054, 1105, 9406, 22878, 15719, 1182, 112, 188, 181, 1361, 9589, 7678, 22556, 117, 1142, 1547, 1138, 1189, 170, 11858, 1482, 112, 188, 2523, 118, 118, 1191, 1178, 3096, 11368, 1182, 1125, 183, 112, 189, 6744, 1113, 9616, 1471, 1107, 1103, 1641, 1648, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n","*** Example ***\n","text: Their film falters , however , in its adherence to the Disney philosophy of required poignancy , a salute that I 'd hoped the movie would avoid .\n","features: InputFeatures(input_ids=[101, 2397, 1273, 175, 1348, 5759, 117, 1649, 117, 1107, 1157, 8050, 21634, 1106, 1103, 5712, 5027, 1104, 2320, 185, 8136, 12149, 7232, 117, 170, 22321, 1115, 146, 112, 173, 4320, 1103, 2523, 1156, 3644, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\n","*** Example ***\n","text: Interacting eyeball-to-eyeball and toe-to-toe , Hopkins and Norton are a winning combination -- but Fiennes steals ` Red Dragon ' right from under their noses .\n","features: InputFeatures(input_ids=[101, 11300, 11179, 1158, 2552, 5892, 118, 1106, 118, 2552, 5892, 1105, 12514, 118, 1106, 118, 12514, 117, 10055, 1105, 10685, 1132, 170, 2183, 4612, 118, 118, 1133, 17355, 26042, 1116, 16867, 169, 2156, 6891, 112, 1268, 1121, 1223, 1147, 3678, 1116, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n","*** Example ***\n","text: Aspires for the piquant but only really achieves a sort of ridiculous sourness .\n","features: InputFeatures(input_ids=[101, 1249, 20082, 1116, 1111, 1103, 185, 28101, 27280, 1133, 1178, 1541, 5515, 1116, 170, 3271, 1104, 9944, 17948, 1757, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\n","*** Example ***\n","text: Exquisitely acted and masterfully if preciously interwoven ... -LRB- the film -RRB- addresses in a fascinating , intelligent manner the intermingling of race , politics and local commerce .\n","features: InputFeatures(input_ids=[101, 16409, 26089, 1193, 5376, 1105, 3283, 5834, 1191, 9692, 1193, 9455, 12821, 7912, 119, 119, 119, 118, 149, 22672, 118, 1103, 1273, 118, 155, 22672, 118, 11869, 1107, 170, 19601, 117, 9998, 4758, 1103, 9455, 5031, 1979, 1104, 1886, 117, 4039, 1105, 1469, 10678, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n"]}]},{"cell_type":"code","metadata":{"id":"j6EjtjScENVw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641475892143,"user_tz":-60,"elapsed":11,"user":{"displayName":"Ander Barrena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgRxXTKl_X28G_aTFKEgcKsBAE_r5TE9B5ziwl2w=s64","userId":"06771498905541655767"}},"outputId":"c9b144d5-997c-45b4-f978-eca4cee651f2"},"source":["test_dataset = test_dataset.batch(32)\n","instances = list(test_dataset.take(1).as_numpy_iterator())\n","instances"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[({'attention_mask': array([[1, 1, 1, ..., 0, 0, 0],\n","          [1, 1, 1, ..., 0, 0, 0],\n","          [1, 1, 1, ..., 0, 0, 0],\n","          ...,\n","          [1, 1, 1, ..., 0, 0, 0],\n","          [1, 1, 1, ..., 0, 0, 0],\n","          [1, 1, 1, ..., 0, 0, 0]], dtype=int32),\n","   'input_ids': array([[  101,  1556, 21555, ...,     0,     0,     0],\n","          [  101,  2397,  1273, ...,     0,     0,     0],\n","          [  101, 11300, 11179, ...,     0,     0,     0],\n","          ...,\n","          [  101,   146,  4819, ...,     0,     0,     0],\n","          [  101, 26517,  8743, ...,     0,     0,     0],\n","          [  101,  1109,  2905, ...,     0,     0,     0]], dtype=int32),\n","   'token_type_ids': array([[0, 0, 0, ..., 0, 0, 0],\n","          [0, 0, 0, ..., 0, 0, 0],\n","          [0, 0, 0, ..., 0, 0, 0],\n","          ...,\n","          [0, 0, 0, ..., 0, 0, 0],\n","          [0, 0, 0, ..., 0, 0, 0],\n","          [0, 0, 0, ..., 0, 0, 0]], dtype=int32)},\n","  array([1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n","         0, 1, 1, 1, 1, 0, 0, 0, 1, 0]))]"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"3iEUS77CIzgA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641475933127,"user_tz":-60,"elapsed":40988,"user":{"displayName":"Ander Barrena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgRxXTKl_X28G_aTFKEgcKsBAE_r5TE9B5ziwl2w=s64","userId":"06771498905541655767"}},"outputId":"f9f8a3fe-bd41-4d40-a1c0-a35cba4d340c"},"source":["model.evaluate(test_dataset)"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["57/57 [==============================] - 29s 507ms/step - loss: 0.3447 - accuracy: 0.9050\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.3447152078151703, 0.9049972295761108]"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"T4d1Hs-Dc4JE"},"source":["## 5. Fine-tuning BERT for NLI\n","\n","Now that you know how to fine-tune BERT model for sentence classification. We could do something similar to fine-tune BERT to Natural Language Inference task. Recall that NLI consist in determining whether a natural language hypothesis can justifiably be inferred from a natural language premise hus given a pair of premise and hypothesis texts, the task is to classify them into three categories: entailment, contradiction, and neutral.\n","\n","There are many ways to approach the task, but one way is to encode the premise and hypothesis at the same time as shown in the figure below. We separate premise and hypothesis sentences with `[SEP]` and use `[CLS]` token to perform the three-way classification task. \n","\n","\n"," ![](http://ixa2.si.ehu.es/~jibloleo/uc3m_dl4nlp/img/bert_nli.png)\n","\n","----\n","\n"]},{"cell_type":"markdown","metadata":{"id":"d50LA3brYajM"},"source":["Let's start loading the data for NLI. We'll use the same function used in the previous lab."]},{"cell_type":"code","metadata":{"id":"Yk-H_xDMYOAw","executionInfo":{"status":"ok","timestamp":1641475955841,"user_tz":-60,"elapsed":22732,"user":{"displayName":"Ander Barrena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgRxXTKl_X28G_aTFKEgcKsBAE_r5TE9B5ziwl2w=s64","userId":"06771498905541655767"}}},"source":["import random\n","import json\n","import bz2\n","import pandas as pd\n","\n","def load_snli_data(path, label_map = {\"entailment\": 0, \"neutral\": 1,\"contradiction\": 2}):\n","    data = []\n","    with bz2.open(path) as f:\n","        for i, line in enumerate(f):\n","            line = line.decode('utf-8')\n","            if i >= 1000000:  # Edit to use less data for debugging. set to 1000000 for testing.\n","                break\n","            json_line = json.loads(line)\n","            if json_line[\"gold_label\"] not in label_map:\n","                continue\n","            loaded_example = {}\n","            loaded_example[\"label\"] = label_map[json_line[\"gold_label\"]]\n","            loaded_example[\"sentence1\"] = json_line[\"sentence1\"]\n","            loaded_example[\"sentence2\"] = json_line[\"sentence2\"]\n","            data.append(loaded_example)\n","    data = pd.DataFrame(data)\n","    return data\n","\n","snli_home = 'drive/My Drive/Colab Notebooks/dl4nlp_labs/data/snli/'  \n","training_set = load_snli_data(snli_home + '/snli_1.0_train.jsonl.bz2')\n","dev_set = load_snli_data(snli_home + '/snli_1.0_dev.jsonl.bz2')\n","test_set = load_snli_data(snli_home + '/snli_1.0_test.jsonl.bz2')"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ksshZRh0lx8K"},"source":["We are going to reduce the dataset to speed up the experiments in the lab session, but feel free to use the whole dataset after the lab is completed. Fine-tuning with the whole training set can take many hours, so maybe it is a good idea to run just for one or two epochs.\n"]},{"cell_type":"code","metadata":{"id":"XHHI8N29Vtti","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641475955842,"user_tz":-60,"elapsed":21,"user":{"displayName":"Ander Barrena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgRxXTKl_X28G_aTFKEgcKsBAE_r5TE9B5ziwl2w=s64","userId":"06771498905541655767"}},"outputId":"dd291b9b-ea4e-48cc-caee-199dcfa262c8"},"source":["training_set = training_set.head(15000)\n","dev_set = dev_set.head(2000)\n","\n","# check if the dataset is still balanced\n","print('Training labels:')\n","print(training_set.label.value_counts())\n","\n","print('Dev labels:')\n","print(dev_set.label.value_counts())"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Training labels:\n","0    5013\n","2    4995\n","1    4992\n","Name: label, dtype: int64\n","Dev labels:\n","1    677\n","0    663\n","2    660\n","Name: label, dtype: int64\n"]}]},{"cell_type":"markdown","metadata":{"id":"OiCVwyaGnFY4"},"source":["Note that when we load the pretrained model (`from_pretrained`) we need to indicate number of labels that contains the dataset. This can be done with the argument `num_labels`."]},{"cell_type":"code","metadata":{"id":"zJdYaECRXN3Y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641475965756,"user_tz":-60,"elapsed":9931,"user":{"displayName":"Ander Barrena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgRxXTKl_X28G_aTFKEgcKsBAE_r5TE9B5ziwl2w=s64","userId":"06771498905541655767"}},"outputId":"ebb94095-ad9e-4ad0-dcd7-87743082067a"},"source":["from transformers import TFBertForSequenceClassification, BertTokenizer\n","\n","nli_model = TFBertForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=3)\n","tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")"],"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n","\n","Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"markdown","metadata":{"id":"UX3s5Yp1rm0a"},"source":["As you can see, the `config` has slightly changed compared to first model. Now it contains the information of the labels (we don't care about the actual id2label mapping for now)."]},{"cell_type":"code","metadata":{"id":"fssORtQtfqwo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641475965758,"user_tz":-60,"elapsed":26,"user":{"displayName":"Ander Barrena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgRxXTKl_X28G_aTFKEgcKsBAE_r5TE9B5ziwl2w=s64","userId":"06771498905541655767"}},"outputId":"99f5837e-86d1-40ed-bff1-0285030683de"},"source":["nli_model.config"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertConfig {\n","  \"_name_or_path\": \"bert-base-cased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"pIFdYyYkTRiF"},"source":["### Exercise 3:\n","For the final exercise you have to re-write the function `convert_examples_to_features` so it is able to extract the token ids of premise and hypothesis in one go. Most of the function is already done for you. You just need to fill a small part to complete it."]},{"cell_type":"code","metadata":{"id":"3zFQ2QNwXLoB","executionInfo":{"status":"ok","timestamp":1641476821587,"user_tz":-60,"elapsed":799,"user":{"displayName":"Ander Barrena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgRxXTKl_X28G_aTFKEgcKsBAE_r5TE9B5ziwl2w=s64","userId":"06771498905541655767"}}},"source":["import tensorflow as tf\n","from transformers import InputFeatures\n","\n","def convert_nli_examples_to_features(premises, hypotheses, labels):\n","  labels = list(labels)\n","\n","  # EXERCISE: Iterate over premises and hypothesis to get tuples of p and h.\n","  \n","  #kk=[]\n","  #for p, h in zip(premises, hypotheses):\n","  #    kk.append((p,h))\n","  #batch_encoding = tokenizer.batch_encode_plus(kk, max_length=128, pad_to_max_length=True)\n","  \n","  #batch_encoding = tokenizer.batch_encode_plus([(p, h) for p, h in zip(premises, hypotheses)],\n","  #                                              max_length=128, pad_to_max_length=True)\n","\n","  batch_encoding = tokenizer.batch_encode_plus(zip(premises, hypotheses),\n","                                               max_length=128, pad_to_max_length=True)\n","  \n","  features = []\n","  for i in range(len(premises)):\n","      inputs = {k: batch_encoding[k][i] for k in batch_encoding}\n","\n","      feature = InputFeatures(**inputs, label=labels[i])\n","      features.append(feature)\n","\n","  for i in range(5):\n","      print(\"*** Example ***\")\n","      print(\"premise: %s\" % (premises[i]))\n","      print(\"hypothesis: %s\" % (hypotheses[i]))\n","      print(\"features: %s\" % features[i])\n","\n","  return features"],"execution_count":24,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sbdPeTBpryJl"},"source":["Once you complete the exercise you can see convert dataset to features first and to `tf.dataset` after that."]},{"cell_type":"code","metadata":{"id":"q6BqLltF32ZU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641476835081,"user_tz":-60,"elapsed":10929,"user":{"displayName":"Ander Barrena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgRxXTKl_X28G_aTFKEgcKsBAE_r5TE9B5ziwl2w=s64","userId":"06771498905541655767"}},"outputId":"acd575f5-175e-41d2-982d-e24eab5a9111"},"source":["train_features = convert_nli_examples_to_features(training_set.sentence1, training_set.sentence2, training_set.label)\n","dev_features = convert_nli_examples_to_features(dev_set.sentence1, dev_set.sentence2, dev_set.label)"],"execution_count":25,"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2232: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["*** Example ***\n","premise: A person on a horse jumps over a broken down airplane.\n","hypothesis: A person is training his horse for a competition.\n","features: InputFeatures(input_ids=[101, 138, 1825, 1113, 170, 3241, 15457, 1166, 170, 3088, 1205, 15478, 119, 102, 138, 1825, 1110, 2013, 1117, 3241, 1111, 170, 2208, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n","*** Example ***\n","premise: A person on a horse jumps over a broken down airplane.\n","hypothesis: A person is at a diner, ordering an omelette.\n","features: InputFeatures(input_ids=[101, 138, 1825, 1113, 170, 3241, 15457, 1166, 170, 3088, 1205, 15478, 119, 102, 138, 1825, 1110, 1120, 170, 20162, 117, 13649, 1126, 184, 10212, 6347, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=2)\n","*** Example ***\n","premise: A person on a horse jumps over a broken down airplane.\n","hypothesis: A person is outdoors, on a horse.\n","features: InputFeatures(input_ids=[101, 138, 1825, 1113, 170, 3241, 15457, 1166, 170, 3088, 1205, 15478, 119, 102, 138, 1825, 1110, 23178, 117, 1113, 170, 3241, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\n","*** Example ***\n","premise: Children smiling and waving at camera\n","hypothesis: They are smiling at their parents\n","features: InputFeatures(input_ids=[101, 4288, 5278, 1105, 12502, 1120, 4504, 102, 1220, 1132, 5278, 1120, 1147, 2153, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n","*** Example ***\n","premise: Children smiling and waving at camera\n","hypothesis: There are children present\n","features: InputFeatures(input_ids=[101, 4288, 5278, 1105, 12502, 1120, 4504, 102, 1247, 1132, 1482, 1675, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\n","*** Example ***\n","premise: Two women are embracing while holding to go packages.\n","hypothesis: The sisters are hugging goodbye while holding to go packages after just eating lunch.\n","features: InputFeatures(input_ids=[101, 1960, 1535, 1132, 9712, 26348, 1229, 2355, 1106, 1301, 15611, 119, 102, 1109, 5919, 1132, 19558, 12903, 1229, 2355, 1106, 1301, 15611, 1170, 1198, 5497, 5953, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n","*** Example ***\n","premise: Two women are embracing while holding to go packages.\n","hypothesis: Two woman are holding packages.\n","features: InputFeatures(input_ids=[101, 1960, 1535, 1132, 9712, 26348, 1229, 2355, 1106, 1301, 15611, 119, 102, 1960, 1590, 1132, 2355, 15611, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\n","*** Example ***\n","premise: Two women are embracing while holding to go packages.\n","hypothesis: The men are fighting outside a deli.\n","features: InputFeatures(input_ids=[101, 1960, 1535, 1132, 9712, 26348, 1229, 2355, 1106, 1301, 15611, 119, 102, 1109, 1441, 1132, 2935, 1796, 170, 3687, 1182, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=2)\n","*** Example ***\n","premise: Two young children in blue jerseys, one with the number 9 and one with the number 2 are standing on wooden steps in a bathroom and washing their hands in a sink.\n","hypothesis: Two kids in numbered jerseys wash their hands.\n","features: InputFeatures(input_ids=[101, 1960, 1685, 1482, 1107, 2221, 14953, 1116, 117, 1141, 1114, 1103, 1295, 130, 1105, 1141, 1114, 1103, 1295, 123, 1132, 2288, 1113, 4122, 3343, 1107, 170, 5056, 1105, 13445, 1147, 1493, 1107, 170, 7496, 119, 102, 1960, 4067, 1107, 8324, 14953, 1116, 10124, 1147, 1493, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\n","*** Example ***\n","premise: Two young children in blue jerseys, one with the number 9 and one with the number 2 are standing on wooden steps in a bathroom and washing their hands in a sink.\n","hypothesis: Two kids at a ballgame wash their hands.\n","features: InputFeatures(input_ids=[101, 1960, 1685, 1482, 1107, 2221, 14953, 1116, 117, 1141, 1114, 1103, 1295, 130, 1105, 1141, 1114, 1103, 1295, 123, 1132, 2288, 1113, 4122, 3343, 1107, 170, 5056, 1105, 13445, 1147, 1493, 1107, 170, 7496, 119, 102, 1960, 4067, 1120, 170, 3240, 18350, 10124, 1147, 1493, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n"]}]},{"cell_type":"code","metadata":{"id":"Vo2EphiZjeNv","executionInfo":{"status":"ok","timestamp":1641476835081,"user_tz":-60,"elapsed":17,"user":{"displayName":"Ander Barrena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgRxXTKl_X28G_aTFKEgcKsBAE_r5TE9B5ziwl2w=s64","userId":"06771498905541655767"}}},"source":["train_dataset = convert_features_to_tf_dataset(train_features)\n","dev_dataset = convert_features_to_tf_dataset(dev_features)"],"execution_count":26,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ObN05ITRsWKe"},"source":["We use `tf.dataset` API to shuffle the training set and set the batch size. We decrease the batch size to 16 in order to avoid problems with the memory. "]},{"cell_type":"code","metadata":{"id":"WECDX7kMctlT","executionInfo":{"status":"ok","timestamp":1641476840756,"user_tz":-60,"elapsed":599,"user":{"displayName":"Ander Barrena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgRxXTKl_X28G_aTFKEgcKsBAE_r5TE9B5ziwl2w=s64","userId":"06771498905541655767"}}},"source":["train_dataset = train_dataset.shuffle(100).batch(16)\n","dev_dataset = dev_dataset.batch(32)"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"fxIlEzupXhG1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641479228768,"user_tz":-60,"elapsed":2385914,"user":{"displayName":"Ander Barrena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgRxXTKl_X28G_aTFKEgcKsBAE_r5TE9B5ziwl2w=s64","userId":"06771498905541655767"}},"outputId":"fc15a98a-2d48-4f01-f853-3160f29933bf"},"source":["# Prepare training: Compile tf.keras model with optimizer, loss and learning rate schedule\n","optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0)\n","loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n","nli_model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n","\n","# Train and evaluate using tf.keras.Model.fit()\n","history = nli_model.fit(train_dataset, epochs=3, validation_data=dev_dataset)\n"],"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","938/938 [==============================] - 806s 832ms/step - loss: 0.6610 - accuracy: 0.7244 - val_loss: 0.4833 - val_accuracy: 0.8175\n","Epoch 2/3\n","938/938 [==============================] - 778s 830ms/step - loss: 0.3850 - accuracy: 0.8609 - val_loss: 0.5156 - val_accuracy: 0.8330\n","Epoch 3/3\n","938/938 [==============================] - 778s 829ms/step - loss: 0.2451 - accuracy: 0.9190 - val_loss: 0.5875 - val_accuracy: 0.8165\n"]}]},{"cell_type":"code","metadata":{"id":"g_tYW0T8d_Qa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641479263497,"user_tz":-60,"elapsed":34741,"user":{"displayName":"Ander Barrena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgRxXTKl_X28G_aTFKEgcKsBAE_r5TE9B5ziwl2w=s64","userId":"06771498905541655767"}},"outputId":"ceddd388-7d0a-4df6-bf57-747c012e661e"},"source":["nli_model.predict(dev_dataset)"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TFSequenceClassifierOutput([('logits',\n","                             array([[-1.4847575 ,  3.753528  , -2.7219157 ],\n","                                    [ 3.291863  , -1.0657724 , -1.8973937 ],\n","                                    [-2.7128737 , -2.1252513 ,  4.8838797 ],\n","                                    ...,\n","                                    [ 2.4189818 , -0.38706732, -1.6479247 ],\n","                                    [-2.1490064 , -0.7249105 ,  2.9523396 ],\n","                                    [ 2.4915164 ,  0.2513971 , -2.544479  ]], dtype=float32))])"]},"metadata":{},"execution_count":29}]},{"cell_type":"markdown","metadata":{"id":"dIgw-1Qot731"},"source":["As in the previous example, we can process the test set in the same way, and evaluate it directly. "]},{"cell_type":"code","metadata":{"id":"NXrIqumjt7XP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641479269514,"user_tz":-60,"elapsed":6028,"user":{"displayName":"Ander Barrena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgRxXTKl_X28G_aTFKEgcKsBAE_r5TE9B5ziwl2w=s64","userId":"06771498905541655767"}},"outputId":"de401249-a925-40e8-ebcb-cc42a6db016c"},"source":["test_features = convert_nli_examples_to_features(test_set.sentence1,\n","                                                 test_set.sentence2,\n","                                                 test_set.label)\n","test_dataset = convert_features_to_tf_dataset(test_features)\n","test_dataset = test_dataset.batch(32)"],"execution_count":30,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2232: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["*** Example ***\n","premise: This church choir sings to the masses as they sing joyous songs from the book at a church.\n","hypothesis: The church has cracks in the ceiling.\n","features: InputFeatures(input_ids=[101, 1188, 1749, 8041, 12792, 1106, 1103, 12980, 1112, 1152, 6928, 8730, 2285, 2040, 1121, 1103, 1520, 1120, 170, 1749, 119, 102, 1109, 1749, 1144, 16694, 1107, 1103, 5265, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n","*** Example ***\n","premise: This church choir sings to the masses as they sing joyous songs from the book at a church.\n","hypothesis: The church is filled with song.\n","features: InputFeatures(input_ids=[101, 1188, 1749, 8041, 12792, 1106, 1103, 12980, 1112, 1152, 6928, 8730, 2285, 2040, 1121, 1103, 1520, 1120, 170, 1749, 119, 102, 1109, 1749, 1110, 2709, 1114, 1461, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\n","*** Example ***\n","premise: This church choir sings to the masses as they sing joyous songs from the book at a church.\n","hypothesis: A choir singing at a baseball game.\n","features: InputFeatures(input_ids=[101, 1188, 1749, 8041, 12792, 1106, 1103, 12980, 1112, 1152, 6928, 8730, 2285, 2040, 1121, 1103, 1520, 1120, 170, 1749, 119, 102, 138, 8041, 4241, 1120, 170, 3866, 1342, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=2)\n","*** Example ***\n","premise: A woman with a green headscarf, blue shirt and a very big grin.\n","hypothesis: The woman is young.\n","features: InputFeatures(input_ids=[101, 138, 1590, 1114, 170, 2448, 4075, 8766, 2087, 117, 2221, 2969, 1105, 170, 1304, 1992, 5207, 119, 102, 1109, 1590, 1110, 1685, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n","*** Example ***\n","premise: A woman with a green headscarf, blue shirt and a very big grin.\n","hypothesis: The woman is very happy.\n","features: InputFeatures(input_ids=[101, 138, 1590, 1114, 170, 2448, 4075, 8766, 2087, 117, 2221, 2969, 1105, 170, 1304, 1992, 5207, 119, 102, 1109, 1590, 1110, 1304, 2816, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\n"]}]},{"cell_type":"code","metadata":{"id":"TrwjUrcKulfv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641479471643,"user_tz":-60,"elapsed":202136,"user":{"displayName":"Ander Barrena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgRxXTKl_X28G_aTFKEgcKsBAE_r5TE9B5ziwl2w=s64","userId":"06771498905541655767"}},"outputId":"1f90e5fc-495e-4650-8536-426743d4ad96"},"source":["nli_model.evaluate(test_dataset)"],"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["307/307 [==============================] - 156s 509ms/step - loss: 0.6086 - accuracy: 0.8030\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.6086451411247253, 0.8030334115028381]"]},"metadata":{},"execution_count":31}]},{"cell_type":"markdown","metadata":{"id":"kjBUT-D2spyT"},"source":["# Atribution:\n","Adapted by Oier Lopez de Lacalle and Ander Barrena"]}]}